{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from langdetect import detect\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_lems.json\", encoding=\"utf8\") as file:\n",
    "    lemmas_by_id = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_by_id = {id: \" \".join(lemmas_by_id[id]) for id in lemmas_by_id}\n",
    "id_by_texts = {texts_by_id[id]: id for id in texts_by_id}\n",
    "texts = list(texts_by_id.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    try:\n",
    "        if detect(text) != \"en\":\n",
    "            del texts[i]\n",
    "    except:\n",
    "        del texts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"english_texts.json\", \"w\") as file:\n",
    "    json.dump(texts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"english_texts.json\") as file:\n",
    "    texts = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = [3, 5, 7, 9]\n",
    "learning_decays = [.7, .9]\n",
    "search_params = {'n_components': n_topics, 'learning_decay': learning_decays}\n",
    "\n",
    "lda = LatentDirichletAllocation(n_jobs=-1)\n",
    "model = GridSearchCV(lda, param_grid=search_params, n_jobs=-1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Log Likelyhoods from Grid Search Output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for decay in learning_decays:\n",
    "    indices = np.where(model.cv_results_['param_learning_decay'] == decay)[0]\n",
    "    scores = model.cv_results_['mean_test_score'][indices]\n",
    "    plt.plot(n_topics, scores, label=str(decay))\n",
    "\n",
    "plt.title(\"Choosing Optimal LDA Model\")\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Log Likelyhood Scores\")\n",
    "plt.legend(title='Learning decay', loc='best')\n",
    "plt.savefig(\"optimal_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model.p\", \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
